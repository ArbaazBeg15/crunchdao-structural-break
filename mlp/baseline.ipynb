{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qU timm neptune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522cd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config(config):\n",
    "    attrs = {}\n",
    "    attrs.update(config.__dict__)\n",
    "\n",
    "    for key, value in config.__class__.__dict__.items():\n",
    "        if not key.startswith('__') and key not in attrs:\n",
    "            attrs[key] = value\n",
    "\n",
    "    for key, value in attrs.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905181fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Config:\n",
    "    model_name = \"mlp.baseline\"\n",
    "    input_dim = 2048\n",
    "    target_dim = 1\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed = 5274\n",
    "\n",
    "    optimizer_name = \"AdamW\"\n",
    "    lr = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    batch_size = 32  # // grad_accum_steps\n",
    "\n",
    "    num_epochs = 100\n",
    "    scheduler_name = \"default\"\n",
    "\n",
    "    dropout = 0.1\n",
    "\n",
    "    hf_token = \"ahf_uOkImkbEroqtIuyvGJrttTzaebfeIdPZID\"\n",
    "    neptune_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "    with_id = \"\"\n",
    "    resume = False\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8981ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(config):\n",
    "    random.seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    torch.manual_seed(config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(config.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "setup_reproducibility(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "login(config.hf_token)\n",
    "repo_id = \"ArbaazBeg/crunchdao-structural-break-detection\"\n",
    "path = snapshot_download(repo_id, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "inputs_path = path+\"/X_train.parquet\"\n",
    "targets_path = path+\"/y_train.parquet\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_parquet(path):\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "inputs_df = load_parquet(inputs_path)\n",
    "targets_df = load_parquet(targets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(inputs_df, targets_df, seed):\n",
    "    targets_df = targets_df.reset_index()\n",
    "\n",
    "    train_ids, test_ids = train_test_split(\n",
    "        targets_df['id'],                     \n",
    "        test_size=0.2,\n",
    "        random_state=seed,\n",
    "        stratify=targets_df['structural_breakpoint']\n",
    "    )\n",
    "\n",
    "    train_inputs = inputs_df.loc[inputs_df.index.get_level_values('id').isin(train_ids)].copy()\n",
    "    eval_inputs = inputs_df.loc[inputs_df.index.get_level_values('id').isin(test_ids)].copy()\n",
    "\n",
    "    train_targets = targets_df[targets_df['id'].isin(train_ids)].set_index('id').copy()\n",
    "    eval_targets = targets_df[targets_df['id'].isin(test_ids)].set_index('id').copy()\n",
    "    \n",
    "    return (\n",
    "        train_inputs,\n",
    "        train_targets, \n",
    "        eval_inputs,\n",
    "        eval_targets\n",
    "    )\n",
    "    \n",
    "data = split(inputs_df, targets_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def preprocess_inputs(inputs_df, dimension=2048):\n",
    "    inputs = []    \n",
    "    for id, seq in inputs_df.groupby(\"id\"):\n",
    "        value = torch.tensor(seq[\"value\"].values).float()\n",
    "        period = torch.tensor(seq[\"period\"].values).float()\n",
    "        input = torch.stack([value, period], axis=0).unsqueeze(0)\n",
    "        input = F.interpolate(input, size=dimension, mode=\"nearest-exact\").squeeze(0)\n",
    "        inputs.append(input) # 2, SEQ LEN\n",
    "        \n",
    "    return torch.stack(inputs)\n",
    "\n",
    "train_inputs = preprocess_inputs(data[0])\n",
    "eval_inputs = preprocess_inputs(data[2])\n",
    "train_inputs.shape, eval_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(target_df):\n",
    "    targets = []\n",
    "    for id, target in target_df.groupby(\"id\"):\n",
    "        target = target[\"structural_breakpoint\"].values.astype(np.float32)\n",
    "        targets.append(torch.tensor(target))\n",
    "    return torch.stack(targets)    \n",
    "\n",
    "train_targets = preprocess_targets(data[1])\n",
    "eval_targets = preprocess_targets(data[3])\n",
    "train_targets.shape, eval_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_and_clamp(train_inputs, eval_inputs):\n",
    "    x = train_inputs[:, 0]\n",
    "    p1 = torch.quantile(x, 0.01)\n",
    "    p99 = torch.quantile(x, 0.99)\n",
    "\n",
    "    print(\"1st percentile:\", p1.item())\n",
    "    print(\"99th percentile:\", p99.item())\n",
    "\n",
    "    x = torch.clamp(x, min=p1.item(), max=p99.item())\n",
    "    eval_inputs[:, 0] = torch.clamp(eval_inputs[:, 0], min=p1.item(), max=p99.item())\n",
    "    train_inputs[:, 0] = x\n",
    "    \n",
    "    return train_inputs, eval_inputs\n",
    "\n",
    "def return_stats(tensor, p=True):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    min, max =  tensor.min(), tensor.max()\n",
    "\n",
    "    if p:\n",
    "        print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "        \n",
    "    return min, max, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cef9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class SequentialDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        inputs, \n",
    "        targets,\n",
    "        mean=None,\n",
    "        std=None,\n",
    "        min=None,\n",
    "        max=None,\n",
    "        minmax=False,\n",
    "        zscore=False,\n",
    "    ):  \n",
    "        inputs = inputs.clone()\n",
    "        targets = targets.clone()\n",
    "        \n",
    "        if zscore:\n",
    "            inputs = self.perform_zscore(inputs, mean, std)\n",
    "        if minmax:\n",
    "            inputs = self.perform_minmax(inputs, min, max)\n",
    "            \n",
    "        assert len(inputs) == len(targets), \"Length Error\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "            \n",
    "    def perform_zscore(self, inputs, mean, std):\n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i][0] = (inputs[i][0] - mean) / std\n",
    "        return inputs\n",
    "\n",
    "    def perform_minmax(self, inputs, min, max):\n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i][0] = (inputs[i][0] - min) / (max - min + 1e-8)\n",
    "        return inputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):   \n",
    "        return self.inputs[index], self.targets[index]\n",
    "\n",
    "train_inputs, eval_inputs = quantile_and_clamp(train_inputs, eval_inputs)\n",
    "min, max, mean, std = return_stats(train_inputs[:, 0])\n",
    "\n",
    "train_ds = SequentialDataset(\n",
    "    inputs=train_inputs, \n",
    "    targets=train_targets, \n",
    "    mean=mean, \n",
    "    std=std,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    zscore=True,\n",
    "    minmax=False\n",
    ")\n",
    "\n",
    "eval_ds = SequentialDataset(\n",
    "    inputs=eval_inputs, \n",
    "    targets=eval_targets, \n",
    "    mean=mean, \n",
    "    std=std,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    zscore=True,\n",
    "    minmax=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c43625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+1)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "train_dl = build_loader(\n",
    "    config.seed,\n",
    "    train_ds,\n",
    "    train=True,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "eval_dl = build_loader(\n",
    "    config.seed,\n",
    "    eval_ds,\n",
    "    train=False,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34012ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features,\n",
    "        dropout,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.norm = nn.BatchNorm1d(2)\n",
    "        self.linear2 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop1(x)\n",
    "        #x = x.view(B, 40, 2)\n",
    "        x = self.norm(x)\n",
    "        #x = x.view(B, 2, 40)\n",
    "        x = self.linear2(x)\n",
    "        x = self.drop2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f67e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_features,\n",
    "        hidden_features, \n",
    "        dropout=0.1,\n",
    "        num_blks=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        blks = []\n",
    "        for i in range(num_blks):\n",
    "            blks.append(\n",
    "                MLPBlock(\n",
    "                    in_features=input_features,\n",
    "                    hidden_features=hidden_features,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "            input_features = hidden_features\n",
    "        self.blks = nn.Sequential(*blks)\n",
    "        self.final = nn.Linear(hidden_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blks(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "model = Model(\n",
    "    input_features=2048,\n",
    "    hidden_features=4096, \n",
    "    dropout=config.dropout,\n",
    "    num_blks=1\n",
    ").to(config.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.lr,\n",
    "    weight_decay=config.weight_decay,\n",
    "    fused=True\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in model.parameters()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "total_training_steps = (len(train_dl)) * config.num_epochs\n",
    "warmup_steps = int(total_training_steps * 0.05)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def remove_orig_mod(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    prefix = \"_orig_mod.\"\n",
    "    for key, value in state_dict.items():\n",
    "        if key.startswith(prefix):\n",
    "            new_key = key[len(prefix):]\n",
    "        else:\n",
    "            new_key = key\n",
    "        new_state_dict[new_key] = value\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "def setup_neptune(config):\n",
    "    if not config.resume:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/bitgrit-air-pollution-1\",\n",
    "            name=config.model_name,\n",
    "            api_token=config.neptune_token\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"model_name\": config.model_name,\n",
    "            \"optimizer_name\": config.optimizer_name,\n",
    "            \"learning_rate\": config.lr,\n",
    "            \"scheduler_name\": config.scheduler_name,\n",
    "            \"weight_decay\": config.weight_decay,\n",
    "            \"dropout\": config.dropout,\n",
    "            \"num_epochs\": config.num_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "        }\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/onward-speed-and-structure\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=config.neptune_token\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    return F.binary_cross_entropy_with_logits(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(preds, targets):\n",
    "    preds = preds.sigmoid().squeeze()\n",
    "    preds = (preds > 0.5).long()\n",
    "    targets = targets.squeeze().long()\n",
    "    return roc_auc_score(targets.numpy(), preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d4243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "            \n",
    "\n",
    "def train_step(model, inputs, targets):\n",
    "    with torch.autocast(device_type=config.device, dtype=torch.float16, cache_enabled=True):\n",
    "        logits = model(inputs)\n",
    "        loss = loss_fn(logits, targets)\n",
    "    return loss, logits, targets\n",
    "\n",
    "\n",
    "def eval_step(model, inputs, targets):\n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type=config.device, dtype=torch.float16, cache_enabled=True):\n",
    "            logits = model(inputs)\n",
    "            loss = loss_fn(logits, targets)\n",
    "    return loss, logits, targets\n",
    "\n",
    "\n",
    "def inference_step(model, inputs):\n",
    "    model.eval() # FIX THIS \n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type=config.device, dtype=torch.float16, cache_enabled=True):\n",
    "            logits = model(inputs)\n",
    "    return logits\n",
    "    \n",
    "\n",
    "def backward_step(loss, optimizer, scaler, scheduler):\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "          \n",
    "    \n",
    "def reduce_outputs(outputs):\n",
    "    data, keys = {}, []\n",
    "    for key in outputs[0].keys():\n",
    "        if outputs[0][key].dim() == 0 and (\"logits\" not in key or \"targets\" not in key):\n",
    "            value = torch.stack([x[key] for x in outputs]).mean().item()\n",
    "            data[key] = value\n",
    "            keys.append(key)\n",
    "            \n",
    "    for i in range(len(outputs)): # delete the scalar and loss keys \n",
    "        for k in keys:\n",
    "            del outputs[i][k]\n",
    "    \n",
    "    o = reduce_dimensional_outputs(outputs)\n",
    "    return data | o\n",
    "\n",
    "\n",
    "def reduce_dimensional_outputs(outputs):\n",
    "    o = {}\n",
    "    for key in outputs[0].keys():\n",
    "        if \"logits\" in key or \"targets\" in key:\n",
    "            tensor = torch.stack([x[key] for x in outputs]).flatten()\n",
    "            o[key] = tensor\n",
    "    return o\n",
    "\n",
    "\n",
    "def save_ckpt(model, metadata, ckpt_path):\n",
    "    data = {\"state_dict\": model.state_dict()}\n",
    "    for k, v in metadata.items():\n",
    "        data[k] = v\n",
    "    torch.save(data, ckpt_path)\n",
    "\n",
    "\n",
    "def log_and_print(neptune_run, data, log=True, print=True):\n",
    "    if log:\n",
    "        for key, value in data.items():\n",
    "            neptune_run[key].append(value)\n",
    "        \n",
    "    if print:\n",
    "        tqdm.write((\n",
    "            f\"Epoch: {data['epoch']}, \"\n",
    "            f\"train/loss: {data['train/loss']:.4f}, \"\n",
    "            f\"eval/loss: {data['eval/loss']:.4f}, \"\n",
    "            f\"train/auroc: {data['train/auroc']:.4f}, \"\n",
    "            f\"eval/auroc: {data['eval/auroc']:.4f}, \"\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac9cf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model, \n",
    "    optimizer,\n",
    "    scaler,  \n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    epoch,\n",
    "    num_epochs,\n",
    "    resume_epoch,\n",
    "    resume, \n",
    "    log_lr_on_step,\n",
    "    neptune_run\n",
    "):\n",
    "    model.train()\n",
    "    pbar = tqdm(\n",
    "        train_dl,\n",
    "        desc=f\"Epoch: {epoch}/{num_epochs}\",\n",
    "        leave=False,\n",
    "        dynamic_ncols=True,\n",
    "        colour=\"red\",\n",
    "        position=1,\n",
    "    )\n",
    "    outputs = []\n",
    "\n",
    "    for index, (inputs, targets) in enumerate(pbar):\n",
    "        if resume and epoch < resume_epoch:\n",
    "            continue\n",
    "        \n",
    "        inputs = inputs.to(config.device, non_blocking=True)\n",
    "        targets = targets.to(config.device, non_blocking=True)\n",
    "    \n",
    "        loss, logits, targets = train_step(model, inputs, targets)\n",
    "        backward_step(loss, optimizer, scaler, scheduler)\n",
    "\n",
    "        outputs.append({\n",
    "            \"train/loss\": loss.detach().cpu(),\n",
    "            \"train/logits\": logits.detach().cpu(),\n",
    "            \"train/targets\": targets.detach().cpu()\n",
    "        })\n",
    "\n",
    "        if log_lr_on_step:\n",
    "            log_and_print(\n",
    "                neptune_run,\n",
    "                data={\"STEP/lr\": scheduler.get_last_lr()[0]}, \n",
    "                log=True, \n",
    "                print=False\n",
    "            )\n",
    "            \n",
    "    return outputs\n",
    "            \n",
    "            \n",
    "def evaluate(model, eval_dl):\n",
    "    model.eval()\n",
    "    pbar = tqdm(\n",
    "        eval_dl,\n",
    "        desc=f\"Evaluating\",\n",
    "        leave=False,\n",
    "        dynamic_ncols=True,\n",
    "        colour=\"blue\",\n",
    "        position=1,\n",
    "    )\n",
    "    outputs = []\n",
    "    \n",
    "    for inputs, targets in pbar:\n",
    "        inputs = inputs.to(config.device, non_blocking=True)\n",
    "        targets = targets.to(config.device, non_blocking=True)\n",
    "        loss, logits, targets = eval_step(model, inputs, targets)\n",
    "        \n",
    "        outputs.append({\n",
    "            \"eval/loss\": loss.detach().cpu(),\n",
    "            \"eval/logits\": logits.detach().cpu(),\n",
    "            \"eval/targets\": targets.detach().cpu()\n",
    "        })\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2178735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/bitgrit-air-pollution-1/e/BIT-118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaaa049ec444fa1a08a8d590827bfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2331351a79a45ee9365bc46e293ecac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63dea9c5bd748318462dc8c3d49a869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 0, train/loss: 0.3847, eval/loss: 0.9667, train/auroc: 0.7330, eval/auroc: 0.4851, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a860c6bf64c7c8b4c2803557bbd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af9302dc574dd78160738d37727a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 1, train/loss: 0.2853, eval/loss: 1.3906, train/auroc: 0.8112, eval/auroc: 0.5061, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8681594b29344ba185db8e7c5dc95dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a6c499df8a4746b4390c148f3fab8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 2, train/loss: 0.2742, eval/loss: 1.4692, train/auroc: 0.8349, eval/auroc: 0.5025, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38140ace1ac4c13a08c7c59b8054aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850fd15bec948358ef67e4d03e4dab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 3, train/loss: 0.2299, eval/loss: 1.8025, train/auroc: 0.8586, eval/auroc: 0.4865, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db30e1af550c4ff6b5e76d6836e613d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbaaea91dcbd4b50bd33da52418c20d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 4, train/loss: 0.1639, eval/loss: 2.0642, train/auroc: 0.8977, eval/auroc: 0.4961, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a9ab5ebaa14f09bd3b56c3b1915f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 5/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed48d79999644fb68be7d69f72328627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 5, train/loss: 0.1444, eval/loss: 2.4672, train/auroc: 0.9115, eval/auroc: 0.4840, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ce5fe5816249b8aa1f430eaa0d75e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 6/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6710e9057014d85ab8333b49dbe3651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 6, train/loss: 0.1787, eval/loss: 2.3721, train/auroc: 0.9100, eval/auroc: 0.5073, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac68039c45a464a86cbf1d917f9087f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 7/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fef54e82174bd9b8da8125d158addc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 7, train/loss: 0.1759, eval/loss: 2.5060, train/auroc: 0.9061, eval/auroc: 0.4917, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7571fafcd34706bf0e2fa7e93e945f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 8/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c425d0d2744274ba7ff43c3fe48f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 8, train/loss: 0.1238, eval/loss: 2.8862, train/auroc: 0.9285, eval/auroc: 0.4897, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371d061ae8004c17ae714470209948a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 9/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead231557a7743519eea5d1d0c24b86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 9, train/loss: 0.0981, eval/loss: 3.2840, train/auroc: 0.9443, eval/auroc: 0.4921, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94285382bfd4ecc941a5ccdd3665c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 10/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17af6be12cbf4c6b841820860c791d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval/loss\n",
      "eval/logits\n",
      "eval/targets\n",
      "Epoch: 10, train/loss: 0.1472, eval/loss: 3.1128, train/auroc: 0.9296, eval/auroc: 0.4887, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9c708fdc974ca690ab705fff3424b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 11/100:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 346 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 346 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/bitgrit-air-pollution-1/e/BIT-118/metadata\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_541/2437553197.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mneptune_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_541/2437553197.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mneptune_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_neptune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         train(\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_541/2437553197.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, train_dl, eval_dl, num_epochs, resume_epoch, resume, log_lr_on_step, neptune_run)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         train_outputs = train_one_epoch(\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_541/1155451164.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scaler, scheduler, train_dl, epoch, num_epochs, resume_epoch, resume, log_lr_on_step, neptune_run)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         outputs.append({\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;34m\"train/loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;34m\"train/logits\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;34m\"train/targets\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    train_dl,\n",
    "    eval_dl, \n",
    "    num_epochs, \n",
    "    resume_epoch,\n",
    "    resume,\n",
    "    log_lr_on_step,\n",
    "    neptune_run\n",
    "):\n",
    "    os.makedirs(\"/ckpts\", exist_ok=True)\n",
    "    train_outputs = []\n",
    "    eval_outputs = []\n",
    "    score = float('-inf')\n",
    "    \n",
    "    scaler = torch.GradScaler()\n",
    "    pbar = tqdm(range(0, num_epochs), position=0, colour=\"green\")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        train_outputs = train_one_epoch(\n",
    "            model,\n",
    "            optimizer, \n",
    "            scaler, \n",
    "            scheduler, \n",
    "            train_dl,\n",
    "            epoch,\n",
    "            num_epochs,\n",
    "            resume_epoch,\n",
    "            resume,\n",
    "            log_lr_on_step,\n",
    "            neptune_run\n",
    "        )\n",
    "        eval_outputs = evaluate(model, eval_dl)\n",
    "        \n",
    "        train_outputs = reduce_outputs(train_outputs)\n",
    "        eval_outputs = reduce_outputs(eval_outputs)\n",
    "        train_outputs[\"train/auroc\"] = metric_fn(train_outputs[\"train/logits\"], train_outputs[\"train/targets\"])\n",
    "        eval_outputs[\"eval/auroc\"] = metric_fn(eval_outputs[\"eval/logits\"], eval_outputs[\"eval/targets\"])\n",
    "        \n",
    "        outputs = train_outputs | eval_outputs\n",
    "        outputs[\"epoch\"] = epoch\n",
    "        del outputs[\"train/logits\"]\n",
    "        del outputs[\"eval/logits\"]\n",
    "        del outputs[\"train/targets\"]\n",
    "        del outputs[\"eval/targets\"]\n",
    "        \n",
    "        log_and_print(neptune_run, outputs)\n",
    "\n",
    "        if outputs[\"eval/auroc\"] > score:\n",
    "            score = outputs[\"eval/auroc\"]\n",
    "            metadata = {\n",
    "                \"train_auroc\": outputs[\"train/auroc\"],\n",
    "                \"eval_auroc\": score,\n",
    "                \"epoch\": epoch\n",
    "            }\n",
    "            save_ckpt(model, metadata, f\"/ckpts/{config.model_name}.pt\")\n",
    "            \n",
    "        #if RMSE >= torch.tensor(0.7000).cuda():\n",
    "        #    break\n",
    "            \n",
    "    neptune_run.stop()\n",
    "    \n",
    "    \n",
    "def start_training():\n",
    "    try:\n",
    "        neptune_run = setup_neptune(config)\n",
    "        train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            scheduler, \n",
    "            train_dl,\n",
    "            eval_dl, \n",
    "            num_epochs=config.num_epochs, \n",
    "            resume_epoch=0,\n",
    "            resume=config.resume,\n",
    "            log_lr_on_step=True,\n",
    "            neptune_run=neptune_run\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        pass\n",
    "        neptune_run.stop()\n",
    "        \n",
    "start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011bb36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
