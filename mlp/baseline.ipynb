{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905181fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def print_config(config):\n",
    "    attrs = {}\n",
    "    attrs.update(config.__dict__)\n",
    "\n",
    "    for key, value in config.__class__.__dict__.items():\n",
    "        if not key.startswith('__') and key not in attrs:\n",
    "            attrs[key] = value\n",
    "\n",
    "    for key, value in attrs.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "class Config:\n",
    "    # Model\n",
    "    model_name = \"tabnet.86.repro.stopping.at.70\"\n",
    "    input_dim = 6\n",
    "    target_dim = 1\n",
    "\n",
    "    # Device & reproducibility\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed = 5274\n",
    "\n",
    "    # Optimization\n",
    "    optimizer_name = \"AdamW\"\n",
    "    lr = 1e-4\n",
    "    weight_decay = 1e-3\n",
    "\n",
    "    batch_size = 1  # // grad_accum_steps\n",
    "\n",
    "    # Training schedule\n",
    "    num_epochs = 100\n",
    "    scheduler_name = \"default\"\n",
    "\n",
    "    # Regularization\n",
    "    dropout = 0.0\n",
    "    drop_path_rate = 0.0\n",
    "    label_smoothing = 0.0\n",
    "\n",
    "    # Experiment tracking\n",
    "    neptune_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "    with_id = \"\"\n",
    "    resume = False\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8981ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(config):\n",
    "    random.seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    torch.manual_seed(config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(config.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "setup_reproducibility(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464f7c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_train.parquet',\n",
       " 'X_train.parquet',\n",
       " '.gitignore',\n",
       " 'X_test.reduced.parquet',\n",
       " 'y_test.reduced.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PATH = \"/Users/arbaaz/Downloads/break/ds\"\n",
    "inputs_path = PATH+\"/X_train.parquet\"\n",
    "targets_path = PATH+\"/y_train.parquet\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ad595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_parquet(path):\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "inputs_df = load_parquet(inputs_path)\n",
    "targets_df = load_parquet(targets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665bd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(inputs_df, targets_df, seed):\n",
    "    targets_df = targets_df.reset_index()\n",
    "\n",
    "    train_ids, test_ids = train_test_split(\n",
    "        targets_df['id'],                     \n",
    "        test_size=0.2,\n",
    "        random_state=seed,\n",
    "        stratify=targets_df['structural_breakpoint']\n",
    "    )\n",
    "\n",
    "    train_inputs = inputs_df.loc[inputs_df.index.get_level_values('id').isin(train_ids)].copy()\n",
    "    eval_inputs = inputs_df.loc[inputs_df.index.get_level_values('id').isin(test_ids)].copy()\n",
    "\n",
    "    train_targets = targets_df[targets_df['id'].isin(train_ids)].set_index('id').copy()\n",
    "    eval_targets = targets_df[targets_df['id'].isin(test_ids)].set_index('id').copy()\n",
    "    \n",
    "    return (\n",
    "        train_inputs,\n",
    "        train_targets, \n",
    "        eval_inputs,\n",
    "        eval_targets\n",
    "    )\n",
    "    \n",
    "data = split(inputs_df, targets_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9f5a0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8000, 2, 2048]), torch.Size([2001, 2, 2048]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def preprocess_inputs(inputs_df, dimension=2048):\n",
    "    inputs = []    \n",
    "    for id, seq in inputs_df.groupby(\"id\"):\n",
    "        value = torch.tensor(seq[\"value\"].values).float()\n",
    "        period = torch.tensor(seq[\"period\"].values).float()\n",
    "        input = torch.stack([value, period], axis=0).unsqueeze(0)\n",
    "        input = F.interpolate(input, size=dimension, mode=\"nearest-exact\").squeeze(0)\n",
    "        inputs.append(input) # 2, SEQ LEN\n",
    "        \n",
    "    return torch.stack(inputs)\n",
    "\n",
    "train_inputs = preprocess_inputs(data[0])\n",
    "eval_inputs = preprocess_inputs(data[2])\n",
    "train_inputs.shape, eval_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5496a317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8000, 1]), torch.Size([2001, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_targets(target_df):\n",
    "    targets = []\n",
    "    for id, target in target_df.groupby(\"id\"):\n",
    "        target = target[\"structural_breakpoint\"].values.astype(np.int32)\n",
    "        targets.append(torch.tensor(target))\n",
    "    return torch.stack(targets)    \n",
    "\n",
    "train_targets = preprocess_targets(data[1])\n",
    "eval_targets = preprocess_targets(data[3])\n",
    "train_targets.shape, eval_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf79f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs_for_zscore(train_inputs, eval_inputs):\n",
    "    x = train_inputs[:, 0]\n",
    "    p1 = torch.quantile(x, 0.01)\n",
    "    p99 = torch.quantile(x, 0.99)\n",
    "\n",
    "    print(\"1st percentile:\", p1.item())\n",
    "    print(\"99th percentile:\", p99.item())\n",
    "\n",
    "    x = torch.clamp(x, min=p1.item(), max=p99.item())\n",
    "    eval_inputs[:, 0] = torch.clamp(eval_inputs[:, 0], min=p1.item(), max=p99.item())\n",
    "    train_inputs[:, 0] = x\n",
    "    \n",
    "    return train_inputs, eval_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80cef9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st percentile: -0.05925929918885231\n",
      "99th percentile: 0.06588339805603027\n",
      "tensor(-0.0593) tensor(0.0659) tensor(0.0004) tensor(0.0163)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class SequentialDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        inputs, \n",
    "        targets,\n",
    "        mean=None,\n",
    "        std=None,\n",
    "        min=None,\n",
    "        max=None,\n",
    "        minmax=False,\n",
    "        zscore=False,\n",
    "    ):  \n",
    "        inputs = inputs.clone()\n",
    "        targets = targets.clone()\n",
    "        \n",
    "        if zscore:\n",
    "            inputs = self.perform_zscore(inputs, mean, std)\n",
    "        if minmax:\n",
    "            inputs = self.perform_minmax(inputs, min, max)\n",
    "            \n",
    "        assert len(inputs) == len(targets), \"Length Error\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "            \n",
    "    def perform_zscore(self, inputs, mean, std):\n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i][0] = (inputs[i][0] - mean) / std\n",
    "        return inputs\n",
    "\n",
    "    def perform_minmax(self, inputs, min, max):\n",
    "        for i in range(len(inputs)):\n",
    "            inputs[i][0] = (inputs[i][0] - min) / (max - min + 1e-8)\n",
    "        return inputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):   \n",
    "        return self.inputs[index], self.targets[index]\n",
    "    \n",
    "\n",
    "train_inputs, eval_inputs = preprocess_inputs_for_zscore(train_inputs, eval_inputs)\n",
    "\n",
    "x = train_inputs[:, 0]\n",
    "mean, std = x.mean(), x.std()\n",
    "min, max =  x.min(), x.max()\n",
    "print(min, max, mean, std)\n",
    "\n",
    "train_ds = SequentialDataset(\n",
    "    inputs=train_inputs, \n",
    "    targets=train_targets, \n",
    "    mean=mean, \n",
    "    std=std,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    zscore=True,\n",
    "    minmax=False\n",
    ")\n",
    "\n",
    "eval_ds = SequentialDataset(\n",
    "    inputs=eval_inputs, \n",
    "    targets=eval_targets, \n",
    "    mean=mean, \n",
    "    std=std,\n",
    "    min=min,\n",
    "    max=max,\n",
    "    zscore=True,\n",
    "    minmax=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3c43625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+1)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "train_dl = build_loader(\n",
    "    config.seed,\n",
    "    train_ds,\n",
    "    train=True,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "eval_dl = build_loader(\n",
    "    config.seed,\n",
    "    eval_ds,\n",
    "    train=False,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56852e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0230) tensor(0.4322)\n",
      "tensor(-0.0188) tensor(0.1495)\n",
      "tensor(-0.0249) tensor(0.2040)\n",
      "tensor(0.0809) tensor(1.0818)\n",
      "tensor(-0.0132) tensor(1.8295)\n",
      "tensor(-0.0174) tensor(0.0879)\n",
      "tensor(-0.0038) tensor(1.1149)\n",
      "tensor(-0.0220) tensor(0.0447)\n",
      "tensor(0.0279) tensor(1.1830)\n",
      "tensor(0.0634) tensor(1.0301)\n",
      "tensor(0.0351) tensor(0.7787)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arbaaz/Library/Python/3.13/lib/python/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "for id, (i, t) in enumerate(train_dl):\n",
    "    print(i[0, 0].mean(), i[0, 0].std())\n",
    "    if id == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3ed9fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0058) tensor(1.0911)\n",
      "tensor(-0.0043) tensor(0.5305)\n",
      "tensor(-0.0077) tensor(0.5707)\n",
      "tensor(-0.0084) tensor(0.2564)\n",
      "tensor(0.0114) tensor(1.2874)\n",
      "tensor(-0.0233) tensor(0.3770)\n",
      "tensor(0.0180) tensor(0.7214)\n",
      "tensor(0.0364) tensor(0.8269)\n",
      "tensor(0.0278) tensor(1.3101)\n",
      "tensor(-0.0292) tensor(0.1756)\n",
      "tensor(-0.0662) tensor(1.6382)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arbaaz/Library/Python/3.13/lib/python/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "for id, (i, t) in enumerate(eval_dl):\n",
    "    print(i[0, 0].mean(), i[0, 0].std())\n",
    "    if id == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b3a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
