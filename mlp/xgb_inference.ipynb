{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53089f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_features(df: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    before = df[df[\"period\"] == 0][\"value\"]\n",
    "    after = df[df[\"period\"] == 1][\"value\"]\n",
    "\n",
    "    features = {\n",
    "        \"mean_diff\": after.mean() - before.mean(),\n",
    "        \"std_diff\": after.std() - before.std(),\n",
    "        \"median_diff\": after.median() - before.median(),\n",
    "        \"iqr_diff\": (\n",
    "            np.percentile(after, 75) - np.percentile(after, 25)\n",
    "        ) - (\n",
    "            np.percentile(before, 75) - np.percentile(before, 25)\n",
    "        ),\n",
    "        \"mean_ratio\": after.mean() / (before.mean() + 1e-8),\n",
    "        \"std_ratio\": after.std() / (before.std() + 1e-8),\n",
    "        \"skew_diff\": after.skew() - before.skew(),\n",
    "        \"kurtosis_diff\": after.kurtosis() - before.kurtosis(),\n",
    "        \"min_diff\": after.min() - before.min(),\n",
    "        \"max_diff\": after.max() - before.max(),\n",
    "    }\n",
    "\n",
    "    return pd.Series(features).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127677c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    model_directory_path: str,\n",
    "):\n",
    "    # For our baseline t-test approach, we don't need to train a model\n",
    "    # This is essentially an unsupervised approach calculated at inference time\n",
    "    model = None\n",
    "\n",
    "    # You could enhance this by training an actual model, for example:\n",
    "    # 1. Extract features from before/after segments of each time series\n",
    "    # 2. Train a classifier using these features and y_train labels\n",
    "    # 3. Save the trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36625299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing \n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def infer(\n",
    "    X_test: typing.Iterable[pd.DataFrame],\n",
    "    model_directory_path: str,\n",
    "):  \n",
    "    scaler = joblib.load(os.path.join(model_directory_path, \"scaler.joblib\"))\n",
    "    model = XGBClassifier()  \n",
    "    model.load_model(os.path.join(model_directory_path, \"xgb.json\"))\n",
    "    yield\n",
    "    \n",
    "    for i in X_test:\n",
    "        f = extract_features(i)\n",
    "        i = i.reshape(1, -1)\n",
    "        i = scaler.transform(i)\n",
    "        prediction = model.predict_proba(i)[:, 1]\n",
    "        prediction = prediction.astype(np.float64)\n",
    "        yield prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff8bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
